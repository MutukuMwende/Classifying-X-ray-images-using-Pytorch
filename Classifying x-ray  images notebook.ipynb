{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85dc467a-5830-44c0-ab74-435be0e5593c",
   "metadata": {},
   "source": [
    "Pneumonia is one of the leading respiratory illnesses worldwide, and its timely and accurate diagnosis is crucial for effective treatment. Manually reviewing chest X-rays plays a critical role in this process, but AI can significantly expedite and enhance assessments.\n",
    "\n",
    "In this project, I explored the ability of a deep learning model to distinguish pneumonia cases from normal lung X-ray images. I fine-tuned a pre-trained ResNet-18 convolutional neural network to classify X-rays into two categories: normal lungs and those affected by pneumonia. Leveraging the pre-trained weights of ResNet-18 allowed me to create an accurate classifier efficiently, reducing the resources and time needed for training.\n",
    "\n",
    "## The Data\n",
    "\n",
    "<img src=\"x-rays_sample.png\" align=\"center\"/>\n",
    "&nbsp\n",
    "\n",
    "The dataset consisted of 300 chest X-rays for training and 100 for testing, evenly divided between NORMAL and PNEUMONIA categories. The images had been preprocessed and organized into train and test folders, with data loaders ready for use with PyTorch. This project highlights my ability to implement advanced deep learning techniques in a healthcare context, showcasing how AI improves diagnostic processes.ses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0f522b79-2a5a-4472-adb9-0d924870bfa1",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 3074,
    "lastExecutedAt": 1733403974567,
    "lastExecutedByKernel": "13046523-b15f-47cc-8175-b2751ab4a4e6",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# # Make sure to run this cell to use torchmetrics.\n!pip install torch torchvision torchmetrics",
    "outputsMetadata": {
     "0": {
      "height": 514,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.13.0)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (0.14.0)\n",
      "Requirement already satisfied: torchmetrics in /home/repl/.local/lib/python3.8/site-packages (1.5.2)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.8/dist-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.8/dist-packages (from torch) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.8/dist-packages (from torch) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.8/dist-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (65.6.3)\n",
      "Requirement already satisfied: wheel in /usr/local/lib/python3.8/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.38.4)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision) (1.23.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision) (9.2.0)\n",
      "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (23.2)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in /home/repl/.local/lib/python3.8/site-packages (from torchmetrics) (0.11.9)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->torchvision) (2.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->torchvision) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->torchvision) (2019.11.28)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# # Make sure to run this cell to use torchmetrics.\n",
    "!pip install torch torchvision torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cb1bedee-bcd5-4c80-a5ed-93df89af0295",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 54,
    "lastExecutedAt": 1733403974623,
    "lastExecutedByKernel": "13046523-b15f-47cc-8175-b2751ab4a4e6",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Import required libraries\n# Data loading\nimport random\nimport numpy as np\nfrom torchvision.transforms import transforms\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader\n\n# Train model\nimport torch\nfrom torchvision import models\nimport torch.nn as nn\nimport torch.optim as optim\n\n# Evaluate model\nfrom torchmetrics import Accuracy, F1Score\n\n# Set random seeds for reproducibility\ntorch.manual_seed(101010)\nnp.random.seed(101010)\nrandom.seed(101010)"
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "# Data loading\n",
    "import random\n",
    "import numpy as np\n",
    "from torchvision.transforms import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Train model\n",
    "import torch\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Evaluate model\n",
    "from torchmetrics import Accuracy, F1Score\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(101010)\n",
    "np.random.seed(101010)\n",
    "random.seed(101010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "dd91680d-cb63-4876-9a51-4ee6bb250c7d",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 49,
    "lastExecutedAt": 1733403974672,
    "lastExecutedByKernel": "13046523-b15f-47cc-8175-b2751ab4a4e6",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "import os\nimport zipfile\n\n# Unzip the data folder\nif not os.path.exists('data/chestxrays'):\n    with zipfile.ZipFile('data/chestxrays.zip', 'r') as zip_ref:\n        zip_ref.extractall('data')"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "# Unzip the data folder\n",
    "if not os.path.exists('data/chestxrays'):\n",
    "    with zipfile.ZipFile('data/chestxrays.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0cc5591a-8dc1-4d7f-88d2-3b1a59fb2a5f",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 47,
    "lastExecutedAt": 1733403974719,
    "lastExecutedByKernel": "13046523-b15f-47cc-8175-b2751ab4a4e6",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# The images need to be normalized to the same domain as the original training data of ResNet-18 network.\n# Normalize the X-rays using transforms.\n# standard deviations of the three color channels, (R,G,B), from the original ResNet-18 training dataset.\ntransform_mean = [0.485, 0.456, 0.406]\ntransform_std =[0.229, 0.224, 0.225]\ntransform = transforms.Compose([transforms.ToTensor(), \n                                transforms.Normalize(mean=transform_mean, std=transform_std)])\n\n# Apply the image transforms\ntrain_dataset = ImageFolder('data/chestxrays/train', transform=transform)\ntest_dataset = ImageFolder('data/chestxrays/test', transform=transform)\n\n# Create data loaders\ntrain_loader = DataLoader(train_dataset, batch_size=len(train_dataset) // 2, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=len(test_dataset))"
   },
   "outputs": [],
   "source": [
    "# Normalize the X-rays using transforms.\n",
    "# standard deviations of the three color channels, (R,G,B), from the original ResNet-18 training dataset.\n",
    "transform_mean = [0.485, 0.456, 0.406]\n",
    "transform_std =[0.229, 0.224, 0.225]\n",
    "transform = transforms.Compose([transforms.ToTensor(), \n",
    "                                transforms.Normalize(mean=transform_mean, std=transform_std)])\n",
    "\n",
    "# Apply the image transforms\n",
    "train_dataset = ImageFolder('data/chestxrays/train', transform=transform)\n",
    "test_dataset = ImageFolder('data/chestxrays/test', transform=transform)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=len(train_dataset) // 2, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c99cf95b-83f3-49e4-9777-4e70736452d8",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 186,
    "lastExecutedAt": 1733403974905,
    "lastExecutedByKernel": "13046523-b15f-47cc-8175-b2751ab4a4e6",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Instantiate the model\n# Load the pre-trained ResNet-18 model\nresnet18 = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)",
    "outputsMetadata": {
     "0": {
      "height": 59,
      "type": "stream"
     }
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "# Load the pre-trained ResNet-18 model\n",
    "resnet18 = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a0d3bc0c-c779-4c24-a7ec-c2a2c9a46549",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 53,
    "lastExecutedAt": 1733403974959,
    "lastExecutedByKernel": "13046523-b15f-47cc-8175-b2751ab4a4e6",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Modify the model\n# Freeze the parameters of the model\nfor param in resnet18.parameters():\n    param.requires_grad = False\n\n# Modify the final layer for binary classification\nresnet18.fc = nn.Linear(resnet18.fc.in_features, 1)"
   },
   "outputs": [],
   "source": [
    "# Modify the model\n",
    "# Freeze the parameters of the model\n",
    "for param in resnet18.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Modify the final layer for binary classification\n",
    "resnet18.fc = nn.Linear(resnet18.fc.in_features, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "99d9bd21-2cbb-4056-a187-48c171af798b",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 56,
    "lastExecutedAt": 1733403975015,
    "lastExecutedByKernel": "13046523-b15f-47cc-8175-b2751ab4a4e6",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Define the training loop\n# Model training/fine-tuning loop\ndef train(model, train_loader, criterion, optimizer, num_epochs):\n    \n    # Train the model for the specified number of epochs\n    for epoch in range(num_epochs):\n        # Set the model to train mode\n        model.train()\n\n        # Initialize the running loss and accuracy\n        running_loss = 0.0\n        running_accuracy = 0\n\n        # Iterate over the batches of the train loader\n        for inputs, labels in train_loader:\n\n            # Zero the optimizer gradients\n            optimizer.zero_grad()\n            \n            # Ensure labels have the same dimensions as outputs\n            labels = labels.float().unsqueeze(1)\n\n            # Forward pass\n            outputs = model(inputs)\n            preds = torch.sigmoid(outputs) > 0.5 # Binary classification\n            loss = criterion(outputs, labels)\n\n            # Backward pass and optimizer step\n            loss.backward()\n            optimizer.step()\n\n            # Update the running loss and accuracy\n            running_loss += loss.item() * inputs.size(0)\n            running_accuracy += torch.sum(preds == labels.data)\n\n        # Calculate the train loss and accuracy for the current epoch\n        train_loss = running_loss / len(train_dataset)\n        train_acc = running_accuracy.double() / len(train_dataset)\n\n        # Print the epoch results\n        print('Epoch [{}/{}], train loss: {:.4f}, train acc: {:.4f}'\n              .format(epoch+1, num_epochs, train_loss, train_acc))\n"
   },
   "outputs": [],
   "source": [
    "# Define the training loop\n",
    "# Model training/fine-tuning loop\n",
    "def train(model, train_loader, criterion, optimizer, num_epochs):\n",
    "    \n",
    "    # Train the model for the specified number of epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        # Set the model to train mode\n",
    "        model.train()\n",
    "\n",
    "        # Initialize the running loss and accuracy\n",
    "        running_loss = 0.0\n",
    "        running_accuracy = 0\n",
    "\n",
    "        # Iterate over the batches of the train loader\n",
    "        for inputs, labels in train_loader:\n",
    "\n",
    "            # Zero the optimizer gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Ensure labels have the same dimensions as outputs\n",
    "            labels = labels.float().unsqueeze(1)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            preds = torch.sigmoid(outputs) > 0.5 # Binary classification\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass and optimizer step\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update the running loss and accuracy\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_accuracy += torch.sum(preds == labels.data)\n",
    "\n",
    "        # Calculate the train loss and accuracy for the current epoch\n",
    "        train_loss = running_loss / len(train_dataset)\n",
    "        train_acc = running_accuracy.double() / len(train_dataset)\n",
    "\n",
    "        # Print the epoch results\n",
    "        print('Epoch [{}/{}], train loss: {:.4f}, train acc: {:.4f}'\n",
    "              .format(epoch+1, num_epochs, train_loss, train_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e51a7e2e-5e0f-4f17-b2ff-78004551390c",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 71121,
    "lastExecutedAt": 1733404046136,
    "lastExecutedByKernel": "13046523-b15f-47cc-8175-b2751ab4a4e6",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "#Fine-tune the model       \n# Set the model to ResNet-18\nmodel = resnet18\n\n# Fine-tune the ResNet-18 model for 3 epochs using the train_loader\noptimizer = torch.optim.Adam(model.fc.parameters(), lr=0.01)\ncriterion = torch.nn.BCEWithLogitsLoss()\ntrain(model, train_loader, criterion, optimizer, num_epochs=3)",
    "outputsMetadata": {
     "0": {
      "height": 80,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], train loss: 1.3915, train acc: 0.4567\n",
      "Epoch [2/3], train loss: 0.8973, train acc: 0.4633\n",
      "Epoch [3/3], train loss: 0.9199, train acc: 0.5033\n"
     ]
    }
   ],
   "source": [
    "#Fine-tune the model       \n",
    "# Set the model to ResNet-18\n",
    "model = resnet18\n",
    "\n",
    "# Fine-tune the ResNet-18 model for 3 epochs using the train_loader\n",
    "optimizer = torch.optim.Adam(model.fc.parameters(), lr=0.01)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "train(model, train_loader, criterion, optimizer, num_epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7e0e1ad6-2f78-4a14-943b-8cc7c9dfe960",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 7952,
    "lastExecutedAt": 1733404054089,
    "lastExecutedByKernel": "13046523-b15f-47cc-8175-b2751ab4a4e6",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Evaluate the model\n\n# Set model to evaluation mode\nmodel = resnet18\nmodel.eval()\n\n# Initialize metrics for accuracy and F1 score\naccuracy_metric = Accuracy(task=\"binary\")\nf1_metric = F1Score(task=\"binary\")\n\n# Create lists store all predictions and labels\nall_preds = []\nall_labels = []\n\n# Disable gradient calculation for evaluation\nwith torch.no_grad():\n  for inputs, labels in test_loader:\n    # Forward pass\n    outputs = model(inputs)\n    preds = torch.sigmoid(outputs).round()  # Round to 0 or 1\n\n    # Extend the lists with predictions and labels\n    all_preds.extend(preds.tolist())\n    all_labels.extend(labels.unsqueeze(1).tolist())\n\n  # Convert lists back to tensors\n  all_preds = torch.tensor(all_preds)\n  all_labels = torch.tensor(all_labels)\n\n  # Calculate accuracy and F1 score\n  test_accuracy = accuracy_metric(all_preds, all_labels).item()\n  test_f1_score = f1_metric(all_preds, all_labels).item()\n  print(f\"\\nTest accuracy: {test_acc:.3f}\\nTest F1-score: {test_f1:.3f}\")",
    "outputsMetadata": {
     "0": {
      "height": 80,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test accuracy: 0.580\n",
      "Test F1-score: 0.704\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model = resnet18\n",
    "model.eval()\n",
    "\n",
    "# Initialize metrics for accuracy and F1 score\n",
    "accuracy_metric = Accuracy(task=\"binary\")\n",
    "f1_metric = F1Score(task=\"binary\")\n",
    "\n",
    "# Create lists store all predictions and labels\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "# Disable gradient calculation for evaluation\n",
    "with torch.no_grad():\n",
    "  for inputs, labels in test_loader:\n",
    "    # Forward pass\n",
    "    outputs = model(inputs)\n",
    "    preds = torch.sigmoid(outputs).round()  # Round to 0 or 1\n",
    "\n",
    "    # Extend the lists with predictions and labels\n",
    "    all_preds.extend(preds.tolist())\n",
    "    all_labels.extend(labels.unsqueeze(1).tolist())\n",
    "\n",
    "  # Convert lists back to tensors\n",
    "  all_preds = torch.tensor(all_preds)\n",
    "  all_labels = torch.tensor(all_labels)\n",
    "\n",
    "  # Calculate accuracy and F1 score\n",
    "  test_accuracy = accuracy_metric(all_preds, all_labels).item()\n",
    "  test_f1_score = f1_metric(all_preds, all_labels).item()\n",
    "  print(f\"\\nTest accuracy: {test_acc:.3f}\\nTest F1-score: {test_f1:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Welcome to DataCamp Workspaces.ipynb",
   "provenance": []
  },
  "editor": "DataLab",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
